{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from random import shuffle, random\n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HaversineDistance(c1, c2): \n",
    "  lon_diff = np.abs(c1[0]-c2[0])*np.pi/360.0\n",
    "  lat_diff = np.abs(c1[1]-c2[1])*np.pi/360.0\n",
    "  a = np.sin(lat_diff)**2 + np.cos(c1[1]*np.pi/180.0) * np.cos(c2[1]*np.pi/180.0) * np.sin(lon_diff)**2\n",
    "  d = 2*6371*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "  return d\n",
    "\n",
    "\n",
    "def load_data(num_records_to_load=10):\n",
    "    submission_df = pd.read_csv('/home/tony/ML/taxi/taxi2_time/test.csv')\n",
    "    submission_df['POLYLINE'] = submission_df['POLYLINE'].apply(json.loads)\n",
    "    submission_df['COORDS_LEN'] = submission_df['POLYLINE'].apply(len)\n",
    "    submission_df['START'] = submission_df['POLYLINE'].apply(lambda x: x[0])\n",
    "\n",
    "    # read train\n",
    "    taxi_df = pd.read_csv('/home/tony/ML/taxi/taxi2_time/train.csv', nrows=num_records_to_load)\n",
    "    taxi_df['POLYLINE'] = taxi_df['POLYLINE'].apply(json.loads)\n",
    "    taxi_df['COORDS_LEN'] = taxi_df['POLYLINE'].apply(len)\n",
    "    taxi_df = taxi_df[taxi_df.COORDS_LEN > 10]\n",
    "    taxi_df['START'] = taxi_df['POLYLINE'].apply(lambda x: x[0])\n",
    "    taxi_df['END'] = taxi_df['POLYLINE'].apply(lambda x: x[-1])\n",
    "    \n",
    "    return taxi_df, submission_df\n",
    "\n",
    "\n",
    "def createTrainTestSplit(df, percent_test=0.1):\n",
    "    num_rows = len(df)\n",
    "    num_train = num_rows - int(num_rows*percent_test)\n",
    "    mask = np.random.rand(num_rows) > percent_test\n",
    "    \n",
    "    train_df, test_df = df[mask], df[~mask]\n",
    "    train_time, test_time = 15*train_df['COORDS_LEN'].values, 15*test_df['COORDS_LEN'].values\n",
    "    train_end, test_end = train_df['END'].values, test_df['END'].values\n",
    "\n",
    "    # Save reference to complete path for analytical purposes\n",
    "    test_df['POLYLINE_ACTUAL'] = test_df['POLYLINE'].values[:]\n",
    "    \n",
    "    #Create partial paths for the test data\n",
    "    #coords = test_df['POLYLINE'].values[:]\n",
    "    #partial_lengths = [round(0.5*len(coord)) for coord in coords]\n",
    "    #test_df['POLYLINE'] = [coords[:n] for n in partial_lengths]\n",
    "    test_df['POLYLINE'] = [coord[:int(round(0.5*len(coord)))] for coord in test_df['POLYLINE'].values]\n",
    "    \n",
    "    \n",
    "    #Drop all data that we shouldn't have during training\n",
    "    test_df = test_df.drop(['COORDS_LEN', 'END'], axis=1)\n",
    "    test_df['COORDS_LEN'] = test_df['POLYLINE'].apply(len)\n",
    "    \n",
    "    return train_df, test_df, train_time, test_time, train_end, test_end\n",
    "\n",
    "def travelTimeScore(pred_times, actual_times):\n",
    "    score = np.sqrt(np.mean((np.log(pred_times+1)-np.log(actual_times+1))**2))\n",
    "    return score\n",
    "\n",
    "def travelEndScore(pred_ends, actual_ends):\n",
    "    num_points = len(pred_ends)\n",
    "    preds, actuals = pred_ends.values, actual_ends.values\n",
    "    score = np.mean([HaversineDistance(preds[i], actuals[i]) for i in range(num_points)])\n",
    "    return score\n",
    "    \n",
    "def submitTravelTime(validation_df, filename):\n",
    "    validation_df[['TRIP_ID', 'TRAVEL_TIME']].to_csv(filename, index=False)\n",
    "    \n",
    "def submitTravelDestination(validation_df, filename):\n",
    "    validation_df[['TRIP_ID', 'LATITUDE', 'LONGITUDE']].to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7391660042791557"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2 = np.array([1,2,3]), np.array([12,13,14])\n",
    "np.sqrt(np.mean((np.log(t1+1)-np.log(t2+1))**2)), travelTimeScore(t1, t2)\n",
    "#travelEndScore(train_df['END'][0:4], train_df['END'][5:9])\n",
    "c1, c2 = train_df['END'][0:4], train_df['END'][5:9]\n",
    "#num_points = len(c1)\n",
    "#num_points\n",
    "#[c1[i] for i in range(num_points)]\n",
    "s1 = travelEndScore(c1, c2)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weightedMeanTravelTimes(train, test, num_trips=100):\n",
    "    test['TRAVEL_TIME'] = 0\n",
    "    for idx, start_coord in enumerate(test['START']):\n",
    "        dists = train['START'].apply(lambda x: HaversineDistance(x, start_coord))\n",
    "        smallest_dist_indexes = np.argpartition(dists, num_trips)[0:num_trips]\n",
    "        w = np.maximum(dists.iloc[smallest_dist_indexes], 0.01)\n",
    "        path_lengths = train.iloc[smallest_dist_indexes]['COORDS_LEN']\n",
    "        no_path_lengths_indexes = np.argpartition(path_lengths, int(num_trips*.95))[0:int(num_trips*.95)]\n",
    "        print idx\n",
    "        #print \"test[idx, travel_time]: \", test[idx, 'TRAVEL_TIME']\n",
    "        print \"test.loc(idx, coords_len): \", test.loc[idx, \"COORDS_LEN\"]\n",
    "        print \"avg: \", np.average(s.iloc[no_path_lengths_indexes], weights=1/w.iloc[no_path_lengths_indexes]**2)\n",
    "        #test.loc[idx, 'TRAVEL_TIME'] = 15*np.maximum(test.loc[idx, 'COORDS_LEN'], np.average(s.iloc[no_path_lengths_indexes], weights=1/w.iloc[no_path_lengths_indexes]**2))\n",
    "        test.loc[idx, 'TRAVEL_TIME'] = 15*np.maximum(test.loc[idx, 'COORDS_LEN'], np.average(path_lengths.iloc[no_path_lengths_indexes], weights=1/w.iloc[no_path_lengths_indexes]**2))\n",
    "\n",
    "        \n",
    "    test['TRAVEL_TIME'] = test['TRAVEL_TIME'].astype(int)\n",
    "    return test['TRAVEL_TIME'].values\n",
    "\n",
    "\n",
    "def weightedMeanTravelTimes3(train, test, num_trips=100):\n",
    "    test_times = np.zeros(len(test))\n",
    "    for idx, start_coord in enumerate(test['START'].values):\n",
    "        dists = np.array([HaversineDistance(x, start_coord) for x in train['START'].values])\n",
    "        smallest_dist_indexes = np.argpartition(dists, num_trips)[0:num_trips]\n",
    "        w = np.maximum(dists[smallest_dist_indexes], 0.01)\n",
    "        path_lengths = train['COORDS_LEN'].values[smallest_dist_indexes]\n",
    "        no_path_lengths_indexes = np.argpartition(path_lengths, int(num_trips*.95))[0:int(num_trips*.95)]\n",
    "        test_times[idx] = 15*np.maximum(test['COORDS_LEN'].values[idx], np.average(path_lengths[no_path_lengths_indexes], weights=1/w[no_path_lengths_indexes]**2))\n",
    "\n",
    "        \n",
    "    test['TRAVEL_TIME'] = test_times.astype(int)\n",
    "    return test_times\n",
    "\n",
    "\n",
    "\n",
    "def weightedMeanTravelTimes4(train, test, num_trips=100):\n",
    "    test_times = np.zeros(len(test))\n",
    "    train_lens = train['POLYLINE'].apply(len)\n",
    "    for idx, test_coord in enumerate(test['POLYLINE'].values):\n",
    "        dists_starts = np.array([HaversineDistance(x[0], test_coord[0]) for x in train['POLYLINE'].values])\n",
    "        dists_ends = np.array([(HaversineDistance(x[(len(test_coord)-1)], test_coord[-1]) if len(x) > len(test_coord) else 100) for x in train['POLYLINE'].values ])\n",
    "        dists = dists_starts + dists_ends\n",
    "        smallest_dist_indexes = np.argpartition(dists, num_trips)[0:num_trips]\n",
    "        w = np.maximum(dists[smallest_dist_indexes], 0.01)\n",
    "        path_lengths = train['COORDS_LEN'].values[smallest_dist_indexes]\n",
    "        no_path_lengths_indexes = np.argpartition(path_lengths, int(num_trips*.95))[0:int(num_trips*.95)]\n",
    "        test_times[idx] = 15*np.maximum(test['COORDS_LEN'].values[idx], np.average(path_lengths[no_path_lengths_indexes], weights=1/w[no_path_lengths_indexes]**2))\n",
    "\n",
    "        \n",
    "    test['TRAVEL_TIME'] = test_times.astype(int)\n",
    "    return test_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training: 17306    num test: 1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:42: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n"
     ]
    }
   ],
   "source": [
    "num_records = 20000\n",
    "taxi_df, submission_df = load_data(num_records_to_load=num_records)\n",
    "#weightedMeanTravelTimes(taxi_df, submission_df, num_trips=10)\n",
    "\n",
    "train_df, test_df, train_time, test_time, train_end, test_end = createTrainTestSplit(taxi_df, 400*n)\n",
    "print \"num training:\", len(train_df), \"   num test:\", len(test_df)\n",
    "\n",
    "#pred_time = weightedMeanTravelTimes4(train_df, test_df, 5)\n",
    "#print \"score:\", travelTimeScore(pred_time, test_time)\n",
    "\n",
    "validation_time = weightedMeanTravelTimes4(train_df, submission_df, 5)\n",
    "\n",
    "#submit\n",
    "submitTravelTime(submission_df, 'inverse_distance_kernel_2_points_B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test.loc(idx, coords_len):  23\n",
      "avg:  36.066944722\n",
      "1\n",
      "test.loc(idx, coords_len): "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'the label [1] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-300-8f1469faf970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweightedMeanTravelTimes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-297-c9ec1654f1b9>\u001b[0m in \u001b[0;36mweightedMeanTravelTimes\u001b[1;34m(train, test, num_trips)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#print \"test[idx, travel_time]: \", test[idx, 'TRAVEL_TIME']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"test.loc(idx, coords_len): \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"COORDS_LEN\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"avg: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mno_path_lengths_indexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mno_path_lengths_indexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#test.loc[idx, 'TRAVEL_TIME'] = 15*np.maximum(test.loc[idx, 'COORDS_LEN'], np.average(s.iloc[no_path_lengths_indexes], weights=1/w.iloc[no_path_lengths_indexes]**2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tony/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tony/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tony/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_is_label_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m                 \u001b[1;31m# we have yielded a scalar ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tony/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis, validate_iterable)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tony/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1247\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tony/anaconda/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \"cannot use label indexing with a null key\")\n\u001b[0;32m   1235\u001b[0m                 raise KeyError(\"the label [%s] is not in the [%s]\" %\n\u001b[1;32m-> 1236\u001b[1;33m                                (key, self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [1] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "pred_time = weightedMeanTravelTimes(train_df, test_df,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
