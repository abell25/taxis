{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from random import shuffle, random\n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HaversineDistance(c1, c2): \n",
    "  lon_diff = np.abs(c1[0]-c2[0])*np.pi/360.0\n",
    "  lat_diff = np.abs(c1[1]-c2[1])*np.pi/360.0\n",
    "  a = np.sin(lat_diff)**2 + np.cos(c1[1]*np.pi/180.0) * np.cos(c2[1]*np.pi/180.0) * np.sin(lon_diff)**2\n",
    "  d = 2*6371*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "  return d\n",
    "\n",
    "def EuclidDistance(c1, c2):\n",
    "    return np.sqrt((c1[0]-c2[0])**2 + (c1[1]-c2[1])**2)\n",
    "\n",
    "\n",
    "def load_data(num_records_to_load=10):\n",
    "    submission_df = pd.read_csv('/home/tony/ML/taxi/taxi2_time/test.csv')\n",
    "    submission_df['POLYLINE'] = submission_df['POLYLINE'].apply(json.loads)\n",
    "    submission_df['COORDS_LEN'] = submission_df['POLYLINE'].apply(len)\n",
    "    submission_df['START'] = submission_df['POLYLINE'].apply(lambda x: x[0])\n",
    "\n",
    "    # read train\n",
    "    taxi_df = pd.read_csv('/home/tony/ML/taxi/taxi2_time/train.csv', nrows=num_records_to_load)\n",
    "    taxi_df['POLYLINE'] = taxi_df['POLYLINE'].apply(json.loads)\n",
    "    taxi_df['COORDS_LEN'] = taxi_df['POLYLINE'].apply(len)\n",
    "    taxi_df = taxi_df[taxi_df.COORDS_LEN > 10]\n",
    "    taxi_df['START'] = taxi_df['POLYLINE'].apply(lambda x: x[0])\n",
    "    taxi_df['END'] = taxi_df['POLYLINE'].apply(lambda x: x[-1])\n",
    "    \n",
    "    return taxi_df, submission_df\n",
    "\n",
    "\n",
    "def createTrainTestSplit(df, percent_test=0.1):\n",
    "    num_rows = len(df)\n",
    "    num_train = num_rows - int(num_rows*percent_test)\n",
    "    mask = np.random.rand(num_rows) > percent_test\n",
    "    \n",
    "    train_df, test_df = df[mask], df[~mask]\n",
    "    train_time, test_time = 15*train_df['COORDS_LEN'].values, 15*test_df['COORDS_LEN'].values\n",
    "    train_end, test_end = train_df['END'].values, test_df['END'].values\n",
    "\n",
    "    # Save reference to complete path for analytical purposes\n",
    "    test_df['POLYLINE_ACTUAL'] = test_df['POLYLINE'].values[:]\n",
    "    \n",
    "    #Create partial paths for the test data\n",
    "    #coords = test_df['POLYLINE'].values[:]\n",
    "    #partial_lengths = [round(0.5*len(coord)) for coord in coords]\n",
    "    #test_df['POLYLINE'] = [coords[:n] for n in partial_lengths]\n",
    "    test_df['POLYLINE'] = [coord[:int(round(0.5*len(coord)))] for coord in test_df['POLYLINE'].values]\n",
    "    \n",
    "    \n",
    "    #Drop all data that we shouldn't have during training\n",
    "    test_df = test_df.drop(['COORDS_LEN', 'END'], axis=1)\n",
    "    test_df['COORDS_LEN'] = test_df['POLYLINE'].apply(len)\n",
    "    \n",
    "    return train_df, test_df, train_time, test_time, train_end, test_end\n",
    "\n",
    "def travelTimeScore(pred_times, actual_times):\n",
    "    score = np.sqrt(np.mean((np.log(pred_times+1)-np.log(actual_times+1))**2))\n",
    "    return score\n",
    "\n",
    "def travelEndScore(pred_ends, actual_ends):\n",
    "    num_points = len(pred_ends)\n",
    "    preds, actuals = pred_ends, actual_ends\n",
    "    score = np.mean([HaversineDistance(preds[i], actuals[i]) for i in range(num_points)])\n",
    "    return score\n",
    "    \n",
    "def submitTravelTime(validation_df, filename):\n",
    "    validation_df[['TRIP_ID', 'TRAVEL_TIME']].to_csv(filename, index=False)\n",
    "    \n",
    "def submitTravelDestination(validation_df, filename):\n",
    "    validation_df['LATITUDE'] = validation_df['TRAVEL_END'].apply(lambda x: x[1])\n",
    "    validation_df['LONGITUDE'] = validation_df['TRAVEL_END'].apply(lambda x: x[0])\n",
    "    validation_df[['TRIP_ID', 'LATITUDE', 'LONGITUDE']].to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:45: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n"
     ]
    }
   ],
   "source": [
    "num_records = 1000\n",
    "test_size = 20\n",
    "\n",
    "taxi_df, submission_df = load_data(num_records_to_load=num_records)\n",
    "train_df, test_df, train_time, test_time, train_end, test_end = createTrainTestSplit(taxi_df, test_size/float(num_records))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 1, 7, 0, 8, 9, 4, 3, 6, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = range(10)\n",
    "shuffle(idxs)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
